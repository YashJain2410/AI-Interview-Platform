# AI Real-Time Voice Interview Platform

A **real-time, voice-first AI interview system** that conducts adaptive technical and HR interviews using **live speech, multi-LLM orchestration, resume-aware RAG, LLM-based evaluation, and MCP-driven agent architecture.**

Built to demonstrate how modern **AI voice agents and LLM systems are engineered in production**, not just how APIs are used.

## Overview

This platform simulates a **real interviewer**, not a chatbot.

It conducts **live voice interviews** through the browser, dynamically adapts questions based on the candidateâ€™s **resume and job description**, evaluates answers using a **rubric-based LLM scoring engine**, and produces a **structured final interview report**.

**The system is designed with**:

- real-time constraints
- modular AI orchestration
- explainable evaluation
- production-ready architecture

## âœ¨ Key Features

### Real-Time Voice Interview
- Live **WebRTC-based voice interaction**
- **Voice Activity Detection (VAD)** for natural turn-taking
- Low-latency streaming audio pipeline (PCM16 standardized)

### Adaptive AI Interviewer
- Stage-aware questioning (HR / Technical)
- Contextual follow-ups probing **depth and reasoning**
- Prompt-controlled interviewer behavior

### Resume & Job-Aware RAG
- Retrieval-Augmented Generation over:
  - Candidate resume
  - Job description
- FAISS-based vector search with Sentence Transformers
- Structured context injection (no prompt stuffing)

### Multi-LLM Orchestration
- Parallel use of **Gemini** and **Hugging Face models**
- Latency-aware response selection
- Fault-tolerant LLM aggregation

### Interview Scoring & Feedback
- **LLM-as-a-Judge** with explicit evaluation rubric
- Scores across technical depth, clarity, communication, and confidence
- Explainable strengths, weaknesses, and improvement suggestions

### MCP-Based Agent Architecture
- Implements **Model Context Protocol (MCP)**
- Independent context servers for:
  - Interview logic
  - RAG retrieval
  - Evaluation
- Central host orchestrates structured context injection

### Final Interview Report
- Auto-generated at session end
- Aggregated scores, insights, and hiring verdict
- Designed for dashboards, PDFs, and analytics

---

## ðŸ—ï¸ System Architecture

```text
Browser (WebRTC)
   â†“
Voice Activity Detection (VAD)
   â†“
Audio Pipeline (PCM16)
   â”œâ”€â”€ Whisper STT
   â”œâ”€â”€ AI Interviewer (LLM Router)
   â”‚     â”œâ”€â”€ Gemini
   â”‚     â”œâ”€â”€ Hugging Face
   â”‚     â””â”€â”€ LLM Aggregation
   â”œâ”€â”€ Edge TTS
   â†“
WebRTC Audio Output
```

### AI Orchestration Layer
```text
AIInterview
   â†“
MCP Host
   â”œâ”€â”€ Interview Context Server
   â”œâ”€â”€ RAG Context Server
   â”œâ”€â”€ Evaluation Context Server
   â†“
LLM Router
```

### Post-Interview
```text
Session Memory
   â†“
Report Generator
   â†“
Final Interview Report
```

---
## ðŸ› ï¸ Tech Stack

### Frontend
- **WebRTC** â€“ Real-time audio streaming from browser
- **JavaScript (Browser APIs)** â€“ Microphone access & live playback
- **Voice Activity Detection (VAD)** â€“ Natural turn-taking and interruption handling
- **Vercel** â€“ Frontend deployment

### Backend
- **FastAPI** â€“ Async backend & WebSocket server
- **WebSockets** â€“ Real-time interview communication
- **aiortc** â€“ Server-side WebRTC handling
- **AsyncIO** â€“ Concurrent audio and LLM pipelines
- **Render** â€“ Backend deployment

### AI & Machine Learning
- **Google Gemini** â€“ Fast conversational LLM
- **Hugging Face Inference API** â€“ Open-source LLMs
- **Multi-LLM Orchestration** â€“ Latency-aware routing & fallback
- **Whisper (OpenAI)** â€“ Speech-to-Text (STT)
- **Edge TTS (Microsoft Neural Voices)** â€“ Low-latency Text-to-Speech
- **Sentence Transformers** â€“ Text embeddings
- **FAISS** â€“ Vector similarity search
- **Retrieval-Augmented Generation (RAG)** â€“ Resume & JD-aware questioning

### AI System Design
- **Model Context Protocol (MCP)** â€“ Modular agent-based architecture
- **LLM-as-a-Judge** â€“ Rubric-based answer evaluation
- **Prompt Engineering** â€“ Controlled interviewer behavior
- **Session Memory** â€“ Stateful interview tracking
- **Context Orchestration** â€“ Structured prompt injection

### Infrastructure & Tooling
- **Environment-based configuration (`.env`)**
- **Modular project structure**
- **Production-ready async design**
- **Extensible for Docker & CI/CD**

---
## ðŸ“ Project Structure
```text 
ai-voice-interviewer/
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ web/                # WebRTC client
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/                # FastAPI entry point
â”‚   â”œâ”€â”€ realtime/
â”‚   â”‚   â”œâ”€â”€ websocket/      # Interview & audio sockets
â”‚   â”‚   â”œâ”€â”€ webrtc/         # WebRTC tracks & signaling
â”‚   â”‚   â””â”€â”€ audio_stream/   # STT â†’ AI â†’ TTS pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ llm_router/     # Multi-LLM orchestration
â”‚   â”‚   â”œâ”€â”€ rag/            # Resume/JD RAG
â”‚   â”‚   â”œâ”€â”€ prompts/        # Prompt templates
â”‚   â”‚   â””â”€â”€ evaluation/     # Scoring & report generation
â”‚   â”‚
â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â”œâ”€â”€ host/           # MCP orchestrator
â”‚   â”‚   â””â”€â”€ servers/        # Context servers
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/             # Session & evaluation memory
â”‚   â””â”€â”€ infra/              # Config, logging
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ resumes/
â”‚   â”œâ”€â”€ job_descriptions/
â”‚   â””â”€â”€ embeddings/
â”‚
â”œâ”€â”€ scripts/                # Ingestion & testing
â”œâ”€â”€ docs/                   # Architecture & design docs
â””â”€â”€ README.md
```

---

## Deployment

- **Backend** deployed on **Render**
  - Async FastAPI + WebSockets + WebRTC

- **Frontend** deployed on **Vercel**
  - Low-latency static hosting for WebRTC client

- Environment-driven configuration allows seamless scaling and provider switching

---

## Author
**Yash Jain**  
AI / ML Engineer â€¢ Backend Engineer  

> Built with a strong focus on **correctness, scalability, and real-world AI system design**.